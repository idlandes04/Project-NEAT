# Phase 3.1.1: Synthetic Data Generator Implementation Plan

## Overview

This document outlines the plan for Phase 3.1.1 of Project NEAT: the Synthetic Data Generator Integration. This phase involves developing a comprehensive data generation and loading system to support the evaluation of the NEAT architecture, particularly focusing on demonstrating the benefits of test-time learning and component-based architecture.

## Dependencies

- PyTorch for data loading integration
- Core NEAT components for model-specific data preparation
- Test infrastructure for validation

# Phase 3.1.1: Synthetic Data Generator Implementation (Completed)

This document provides an overview of the implementation for Phase 3.1.1 of Project NEAT, which focuses on the synthetic data generator integration. All tests are now passing, and the system is ready for full-scale training on the Windows PC with 3080ti GPU.

## Implementation Overview

The synthetic data generation system is designed to provide diverse mathematical problems at various difficulty levels to evaluate the NEAT architecture's capabilities. It includes:

1. **Basic Data Generation**
   - Core `MathDataGenerator` class for generating mathematical problems
   - Support for multiple problem types and difficulty levels
   - Template-based generation system with varied problem representation

2. **Advanced Problem Types**
   - Multi-step reasoning problems requiring intermediate calculations
   - Algebraic equation problems for solving unknown variables
   - Non-linear sequences with quadratic, exponential, and Fibonacci patterns
   - Component-specific problems to test NEAT architecture features

3. **Component-Specific Problems**
   - **Titans Memory Test**: Problems designed to test long-term memory capabilities
   - **Transformer² Test**: Pattern adaptation problems for testing model adaptability
   - **MVoT-Compatible**: Problems that could benefit from visual thinking
   - **BLT-Friendly**: Problems with varying entropy levels for dynamic patching

4. **Data Loading Infrastructure**
   - PyTorch-compatible dataset and data loader implementations
   - Tokenization for converting text problems to model inputs
   - Efficient batching and preprocessing


``
## Usage

### Generating Problems

```python
from src.data.synthetic.math_generator import MathDataGenerator, DifficultyLevel, ProblemType

# Initialize generator
generator = MathDataGenerator()

# Generate a basic addition problem
problem = generator.generate_problem(
    difficulty=DifficultyLevel.BASIC,
    problem_type=ProblemType.ADDITION
)
print(f"Question: {problem.question}")
print(f"Answer: {problem.answer}")

# Generate a progressive dataset with multiple difficulty levels
problems = generator.generate_progressive_dataset(
    base_size=50,
    include_difficulties=[
        DifficultyLevel.BASIC,
        DifficultyLevel.MEDIUM,
        DifficultyLevel.ADVANCED
    ]
)
```

### Creating Training Datasets

```bash
# Generate training dataset for the NEAT model
python scripts/prepare_training_dataset.py \
    --output_dir ./data/neat_training \
    --general_size 50000 \
    --component_size 10000 \
    --eval_size 10000
```

### End-to-End Training

```bash
# Run the full training pipeline
bash scripts/train_neat_model.sh
```

## Component-Specific Problem Examples

### Titans Memory Test
```
Remember this key-value pair: gamma=42. You will need to recall it later.
```

### Transformer² Adaptation Test
```
Pattern rule: 3→6, 7→14, 10→20. Apply the same rule to find: 15 → ?
```

### Non-Linear Sequence
```
What's the next number in this quadratic sequence: 1, 4, 9, 16?
```

### Multi-Step Problems
```
If you add 5 and 3, then multiply by 2, what do you get?
```

### Algebraic Problems
```
Solve for x: 3x + 5 = 20
```